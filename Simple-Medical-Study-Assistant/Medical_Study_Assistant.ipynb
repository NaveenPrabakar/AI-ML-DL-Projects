{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "os.environ[\"PINECONE_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "SHhcN6F_HNsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf pinecone openai tiktoken orjson python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeSjQlfGHUDM",
        "outputId": "85fb4178-4887-44d1-b59e-645b58664976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.0.0)\n",
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.12/dist-packages (7.3.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.99.9)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.12/dist-packages (3.11.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2025.8.3)\n",
            "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from pinecone) (1.7.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.9.0.post0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.12/dist-packages (from pinecone) (4.14.1)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone) (2.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: packaging<25.0,>=24.2 in /usr/local/lib/python3.12/dist-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (24.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l63jIBe7eisc"
      },
      "outputs": [],
      "source": [
        "import os, uuid, orjson\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from pypdf import PdfReader\n",
        "from openai import OpenAI\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "try:\n",
        "    import tiktoken\n",
        "    ENCODER = tiktoken.get_encoding(\"cl100k_base\")\n",
        "except Exception:\n",
        "    ENCODER = None\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
        "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\", \"\")\n",
        "PINECONE_INDEX  = os.environ.get(\"PINECONE_INDEX\", \"health-rag-index\")\n",
        "\n",
        "EMBED_MODEL = \"text-embedding-3-small\"\n",
        "GEN_MODEL   = \"gpt-4o-mini\"\n",
        "RISK_MODEL  = GEN_MODEL\n",
        "\n",
        "TOP_K = 8\n",
        "MIN_SIM = 0.3\n",
        "CHUNK_TOKENS = 1000\n",
        "CHUNK_OVERLAP = 200\n",
        "DEFAULT_NAMESPACE = \"textbook_01\"\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "# ✅ New SDK: use .list_indexes().names instead of dict indexing\n",
        "if PINECONE_INDEX not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=PINECONE_INDEX,\n",
        "        dimension=1536,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        "    )\n",
        "\n",
        "# ✅ New SDK: Index is a method call\n",
        "index = pc.Index(PINECONE_INDEX)\n",
        "\n"
      ],
      "metadata": {
        "id": "-LUIrvbSJoS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def num_tokens(s: str) -> int:\n",
        "    if ENCODER:\n",
        "        return len(ENCODER.encode(s))\n",
        "    return max(1, len(s.split()) // 0.75)\n",
        "\n",
        "@dataclass\n",
        "class DocChunk:\n",
        "    id: str\n",
        "    text: str\n",
        "    page: int\n",
        "    meta: Dict[str, Any]\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# PDF → Chunks → Pinecone\n",
        "# -----------------------------\n",
        "def pdf_to_pages(path: str) -> List[Tuple[int, str]]:\n",
        "    reader = PdfReader(path)\n",
        "    pages = []\n",
        "    for i, p in enumerate(reader.pages, start=1):\n",
        "        txt = p.extract_text() or \"\"\n",
        "        txt = \"\\n\".join(line.strip() for line in txt.splitlines())\n",
        "        pages.append((i, txt))\n",
        "    return pages\n",
        "\n",
        "def chunk_text(text: str, page: int, tokens: int = CHUNK_TOKENS, overlap: int = CHUNK_OVERLAP) -> List[Tuple[str,int]]:\n",
        "    words, out, buf = text.split(), [], []\n",
        "    for w in words:\n",
        "        buf.append(w)\n",
        "        if num_tokens(\" \".join(buf)) >= tokens:\n",
        "            out.append((\" \".join(buf), page))\n",
        "            buf = buf[-overlap:]\n",
        "    if buf:\n",
        "        out.append((\" \".join(buf), page))\n",
        "    return out\n",
        "\n",
        "def ingest_pdf(path: str, source: str, namespace: str = DEFAULT_NAMESPACE, year: int = 2024) -> int:\n",
        "    pages = pdf_to_pages(path)\n",
        "    chunks: List[DocChunk] = []\n",
        "    for page, txt in pages:\n",
        "        for chunk_txt, p in chunk_text(txt, page):\n",
        "            cid = f\"{source}-{p}-{uuid.uuid4().hex[:8]}\"\n",
        "            chunks.append(DocChunk(\n",
        "                id=cid,\n",
        "                text=chunk_txt,\n",
        "                page=p,\n",
        "                meta={\"source\": source, \"page\": p, \"year\": year, \"namespace\": namespace}\n",
        "            ))\n",
        "    # Embed and upsert\n",
        "    texts = [c.text for c in chunks]\n",
        "    embeds = []\n",
        "    for i in range(0, len(texts), 128):\n",
        "        resp = client.embeddings.create(model=EMBED_MODEL, input=texts[i:i+128])\n",
        "        embeds.extend([d.embedding for d in resp.data])\n",
        "    upserts = [{\"id\":c.id,\"values\":vec,\"metadata\":{**c.meta,\"text\":c.text}} for c,vec in zip(chunks,embeds)]\n",
        "    for i in range(0,len(upserts),100):\n",
        "        index.upsert(vectors=upserts[i:i+100], namespace=namespace)\n",
        "    return len(chunks)\n"
      ],
      "metadata": {
        "id": "rysAtMsvJwI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Retrieval + QA\n",
        "# -----------------------------\n",
        "SYSTEM_PROMPT = (\n",
        "    \"You are a healthcare reference assistant for education.\\n\"\n",
        "    \"Rules: use ONLY provided sources, never guess; avoid diagnosis/dosing; cite like [Source, p.Page].\\n\"\n",
        ")\n",
        "RISK_PROMPT = (\n",
        "    \"Classify query: LOW, MED, HIGH risk.\\n\"\n",
        "    \"HIGH: emergencies, dosing, treatment; MED: conditions, criteria; LOW: definitions, anatomy.\\n\"\n",
        ")\n",
        "DISCLAIMER = \"Educational use only. Not medical advice. Consult a clinician for personal health concerns.\"\n"
      ],
      "metadata": {
        "id": "MQGUdBWhJ0PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_risk(query: str) -> str:\n",
        "    resp = client.chat.completions.create(model=RISK_MODEL,\n",
        "        messages=[{\"role\":\"system\",\"content\":\"You classify risk.\"}, {\"role\":\"user\",\"content\":f\"{RISK_PROMPT}\\nQuery: {query}\"}],\n",
        "        temperature=0)\n",
        "    label = resp.choices[0].message.content.strip().upper()\n",
        "    return label if label in {\"LOW\",\"MED\",\"HIGH\"} else \"MED\"\n",
        "\n",
        "def retrieve(query: str, namespace: str = DEFAULT_NAMESPACE, k: int = TOP_K) -> List[Dict[str, Any]]:\n",
        "    qvec = client.embeddings.create(model=EMBED_MODEL, input=[query]).data[0].embedding\n",
        "    res = index.query(vector=qvec, top_k=k, include_metadata=True, namespace=namespace)\n",
        "    hits = []\n",
        "    for m in res.matches or []:\n",
        "        if getattr(m,\"score\",1.0) >= MIN_SIM:\n",
        "            hits.append({**(m.metadata or {}), \"_score\":m.score, \"_id\":m.id})\n",
        "    return hits\n",
        "\n",
        "def build_messages(query: str, ctx: List[Dict[str, Any]]):\n",
        "    ctx_str = \"\\n---\\n\".join([f\"[{c['source']}, p.{c['page']}]\\n{c['text'][:1000]}\" for c in ctx])\n",
        "    user = f\"Q: {query}\\n\\nContext:\\n{ctx_str}\\n\\nAnswer and cite sources. Add Disclaimer line.\"\n",
        "    return [{\"role\":\"system\",\"content\":SYSTEM_PROMPT},{\"role\":\"user\",\"content\":user}]\n",
        "\n",
        "def answer_query(query: str, namespace: str = DEFAULT_NAMESPACE):\n",
        "    risk = classify_risk(query)\n",
        "    ctx = retrieve(query, namespace, TOP_K)\n",
        "    if not ctx:\n",
        "        return {\"risk\":risk, \"answer\":\"Insufficient info in sources.\", \"citations\":[], \"disclaimer\":DISCLAIMER}\n",
        "    msgs = build_messages(query, ctx)\n",
        "    resp = client.chat.completions.create(model=GEN_MODEL,messages=msgs,temperature=0.2)\n",
        "    return {\"risk\":risk, \"answer\":resp.choices[0].message.content.strip(), \"citations\":[{\"source\":c['source'],\"page\":c['page']} for c in ctx], \"disclaimer\":DISCLAIMER}"
      ],
      "metadata": {
        "id": "1XEJdcrMJ4WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -----------------------------\n",
        "# Fine-tune dataset builder\n",
        "# -----------------------------\n",
        "def build_ft_example(question: str, ctx: List[Dict[str, Any]]):\n",
        "    cites = \", \".join([f\"{c['source']}, p.{c['page']}\" for c in ctx[:3]])\n",
        "    answer = f\"Answer: <your curated answer>\\n\\nCitations: [{cites}]\\nDisclaimer: {DISCLAIMER}\"\n",
        "    return {\"messages\":[{\"role\":\"system\",\"content\":SYSTEM_PROMPT},{\"role\":\"user\",\"content\":question},{\"role\":\"assistant\",\"content\":answer}]}\n",
        "\n",
        "def write_jsonl(records: List[Dict], path: str):\n",
        "    with open(path,\"wb\") as f:\n",
        "        for r in records:\n",
        "            f.write(orjson.dumps(r))\n",
        "            f.write(b\"\\n\")"
      ],
      "metadata": {
        "id": "aUeQv4PbJ6t8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Ingest a PDF textbook:\n",
        "n = ingest_pdf(\"/content/5. Skin Cancer Author Lauren Queen.pdf\", source=\"Harrison's (21e)\", namespace=\"harrison21\")\n",
        "print(\"Chunks indexed\", n)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfZZwfZ9HeZJ",
        "outputId": "02b7fac7-f2f3-4bcf-e32d-0bd6bc8b18d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunks indexed 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Ask a question:\n",
        "result = answer_query(\"I have a new dark mole that’s irregular in shape and sometimes bleeds. Could this be skin cancer?”\", namespace=\"harrison21\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWymn_9PJKAQ",
        "outputId": "1fd7d0d8-1ae5-4e57-f28c-fc26a0690d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'risk': 'MED', 'answer': 'Based on the information provided, a new dark mole that is irregular in shape and sometimes bleeds could potentially be a sign of melanoma, which is a type of skin cancer. Dermatologists use the \"ABCDE\" mnemonic to assess moles for melanoma: Asymmetry, Borders, Color, Diameter, and Evolution over time. If a mole has irregular borders, varying colors, and a diameter greater than 6mm, it is recommended that it be biopsied for further testing [Harrison\\'s (21e), p.5.0].\\n\\nIt is important to consult a dermatologist for a proper evaluation and diagnosis, as skin cancer can manifest in various ways and requires professional assessment.\\n\\n**Disclaimer:** This response is for informational purposes only and is not a substitute for professional medical advice, diagnosis, or treatment. Always seek the advice of your physician or other qualified health provider with any questions you may have regarding a medical condition.', 'citations': [{'source': \"Harrison's (21e)\", 'page': 5.0}, {'source': \"Harrison's (21e)\", 'page': 4.0}, {'source': \"Harrison's (21e)\", 'page': 8.0}, {'source': \"Harrison's (21e)\", 'page': 29.0}, {'source': \"Harrison's (21e)\", 'page': 18.0}, {'source': \"Harrison's (21e)\", 'page': 3.0}, {'source': \"Harrison's (21e)\", 'page': 26.0}, {'source': \"Harrison's (21e)\", 'page': 22.0}], 'disclaimer': 'Educational use only. Not medical advice. Consult a clinician for personal health concerns.'}\n"
          ]
        }
      ]
    }
  ]
}